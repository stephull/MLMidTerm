{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4DCPQWsDb6k"
      },
      "source": [
        "<b>\n",
        "  Stephen Hullender\n",
        "</b>\n",
        "<br/>\n",
        "<span>\n",
        "  CIS 4526 - Foundations in Machine Learning\n",
        "  (Fall 2022)\n",
        "</span>\n",
        "<br/>\n",
        "<span>\n",
        "  Midterm Assignment: Paraphrase Identification\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i54O-M8zDcee"
      },
      "source": [
        "<br/>\n",
        "<h3>Getting Started</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY1fk6n93e6y",
        "outputId": "1f41a98f-aa7d-4d8f-b75d-d7c4a72d64f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "np.set_printoptions(threshold=100)\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', 50)\n",
        "#pd.set_option('display.max_rows', sys.maxsize)\n",
        "\n",
        "# SKlearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, multilabel_confusion_matrix, mean_absolute_error\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# scipy\n",
        "from scipy import linalg\n",
        "from scipy.stats import wasserstein_distance\n",
        "import scipy.spatial as sp\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# other \n",
        "from google.colab import drive, files\n",
        "import pickle\n",
        "import time\n",
        "import re\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "import calendar "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQzy4x1l5tBo",
        "outputId": "3c2f708b-9e52-488f-fc4a-6aac1cb561a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text files have been converted to Pandas DataFrames...\n"
          ]
        }
      ],
      "source": [
        "# define source folder and text file names w/ labels needed for each table\n",
        "SRC = \"gdrive/My Drive/MLMidterm\"\n",
        "SRC_TRAIN = f\"{SRC}/train_with_label.txt\"\n",
        "SRC_DEV = f\"{SRC}/dev_with_label.txt\"\n",
        "SRC_TEST = f\"{SRC}/test_without_label.txt\"\n",
        "LABELS = [\"instance_id\", \"sentence_1\", \"sentence_2\", \"gold_label\"]\n",
        "\n",
        "# conversion of txt to DataFrame\n",
        "def load_txt_to_pd():\n",
        "  global train, dev, test\n",
        "  train = pd.read_csv(SRC_TRAIN, delimiter=\"\\t\", names=LABELS, on_bad_lines='skip', encoding='utf-8')\n",
        "  dev = pd.read_csv(SRC_DEV, delimiter=\"\\t\", names=LABELS, on_bad_lines='skip', encoding='utf-8')\n",
        "  test = pd.read_csv(SRC_TEST, delimiter=\"\\t\", names=LABELS[:-1], on_bad_lines='skip', encoding='utf-8')\n",
        "  # encoding: https://dev.to/_aadidev/3-ways-to-handle-non-utf-8-characters-in-pandas-242\n",
        "  print(\"Text files have been converted to Pandas DataFrames...\")\n",
        "\n",
        "# connect to Google Drive to fetch files\n",
        "try:  \n",
        "  load_txt_to_pd()\n",
        "except:\n",
        "  drive.mount('/content/gdrive')\n",
        "  load_txt_to_pd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxn2251hlze5"
      },
      "source": [
        "<h3>Data Cleaning and Preprocessing</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hjp2jEtt6oOB"
      },
      "outputs": [],
      "source": [
        "# take out nan values from all tables\n",
        "train = train.dropna().reset_index(drop=True)\n",
        "dev = dev.dropna().reset_index(drop=True)\n",
        "test = test.dropna().reset_index(drop=True)\n",
        "\n",
        "# band-aids\n",
        "test = test.drop([69])\n",
        "test.reset_index(inplace=True)\n",
        "\n",
        "final_instance_ids = test['instance_id'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "J5gpD4fd9DoF"
      },
      "outputs": [],
      "source": [
        "# along with LABELS, make a TABLES array\n",
        "TABLES = [train, dev, test]\n",
        "\n",
        "gold_train = train['gold_label'].tolist()\n",
        "gold_dev = dev['gold_label'].tolist()\n",
        "\n",
        "# labels missing (showing text instead) on the following indexes:\n",
        "training_label_band_aids = [\n",
        "    319, 818, 904, 1007, 1076, 1089, 1132, 1258, 1408, 1476, 1546, 1664, 1735, 1789, 1857,\n",
        "    2012, 2088, 2356, 2784, 2999, 3087, 3299, 3368, 3451, 3630, 3813\n",
        "]\n",
        "#corresponding_train_labels = [\n",
        "#    1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1\n",
        "#]\n",
        "corresponding_train_labels = [0] * 26\n",
        "for i in range(len(training_label_band_aids)):\n",
        "  index = training_label_band_aids[i]\n",
        "  gold_train[index] = str(corresponding_train_labels[i])\n",
        "\n",
        "# another band aid\n",
        "dev_label_band_aids = [77, 415, 602]\n",
        "#corresponding_dev_labels = [1, 0, 1]\n",
        "corresponding_dev_labels = [0] * 3\n",
        "for i in range(len(dev_label_band_aids)):\n",
        "  index = dev_label_band_aids[i]\n",
        "  gold_dev[index] = str(corresponding_dev_labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SaSucOejyF2o"
      },
      "outputs": [],
      "source": [
        "contractions = { \n",
        "  \"aren't\": \"are not\",\n",
        "  \"can't\": \"cannot\",\n",
        "  \"can't've\": \"cannot have\",\n",
        "  \"'cause\": \"because\",\n",
        "  \"could've\": \"could have\",\n",
        "  \"couldn't\": \"could not\",\n",
        "  \"couldn't've\": \"could not have\",\n",
        "  \"didn't\": \"did not\",\n",
        "  \"doesn't\": \"does not\",\n",
        "  \"don't\": \"do not\",\n",
        "  \"hadn't\": \"had not\",\n",
        "  \"hadn't've\": \"had not have\",\n",
        "  \"hasn't\": \"has not\",\n",
        "  \"haven't\": \"have not\",\n",
        "  \"he'd\": \"he would\",\n",
        "  \"he'd've\": \"he would have\",\n",
        "  \"he'll\": \"he will\",\n",
        "  \"he'll've\": \"he will have\",\n",
        "  \"he's\": \"he is\",\n",
        "  \"how'd\": \"how did\",\n",
        "  \"how'd'y\": \"how do you\",\n",
        "  \"how'll\": \"how will\",\n",
        "  \"how's\": \"how is\",\n",
        "  \"I'd\": \"I would\",\n",
        "  \"I'd've\": \"I would have\",\n",
        "  \"I'll\": \"I will\",\n",
        "  \"I'll've\": \"I will have\",\n",
        "  \"I'm\": \"I am\",\n",
        "  \"I've\": \"I have\",\n",
        "  \"isn't\": \"is not\",\n",
        "  \"it'd\": \"it would\",\n",
        "  \"it'd've\": \"it would have\",\n",
        "  \"it'll\": \"it will\",\n",
        "  \"it'll've\": \"it will have\",\n",
        "  \"it's\": \"it is\",\n",
        "  \"let's\": \"let us\",\n",
        "  \"ma'am\": \"madam\",\n",
        "  \"mayn't\": \"may not\",\n",
        "  \"might've\": \"might have\",\n",
        "  \"mightn't\": \"might not\",\n",
        "  \"mightn't've\": \"might not have\",\n",
        "  \"must've\": \"must have\",\n",
        "  \"mustn't\": \"must not\",\n",
        "  \"mustn't've\": \"must not have\",\n",
        "  \"needn't\": \"need not\",\n",
        "  \"needn't've\": \"need not have\",\n",
        "  \"o'clock\": \"of the clock\",\n",
        "  \"oughtn't\": \"ought not\",\n",
        "  \"oughtn't've\": \"ought not have\",\n",
        "  \"shan't\": \"shall not\",\n",
        "  \"sha'n't\": \"shall not\",\n",
        "  \"shan't've\": \"shall not have\",\n",
        "  \"she'd\": \"she would\",\n",
        "  \"she'd've\": \"she would have\",\n",
        "  \"she'll\": \"she will\",\n",
        "  \"she'll've\": \"she will have\",\n",
        "  \"she's\": \"she is\",\n",
        "  \"should've\": \"should have\",\n",
        "  \"shouldn't\": \"should not\",\n",
        "  \"shouldn't've\": \"should not have\",\n",
        "  \"so've\": \"so have\",\n",
        "  \"that'd\": \"that had\",\n",
        "  \"that'd've\": \"that would have\",\n",
        "  \"that's\": \"that is\",\n",
        "  \"there'd\": \"there would\",\n",
        "  \"there'd've\": \"there would have\",\n",
        "  \"there's\": \"there is\",\n",
        "  \"they'd\": \"they would\",\n",
        "  \"they'd've\": \"they would have\",\n",
        "  \"they'll\": \"they will\",\n",
        "  \"they'll've\": \"they will have\",\n",
        "  \"they're\": \"they are\",\n",
        "  \"they've\": \"they have\",\n",
        "  \"to've\": \"to have\",\n",
        "  \"wasn't\": \"was not\",\n",
        "  \"we'd\": \"we would\",\n",
        "  \"we'd've\": \"we would have\",\n",
        "  \"we'll\": \"we will\",\n",
        "  \"we'll've\": \"we will have\",\n",
        "  \"we're\": \"we are\",\n",
        "  \"we've\": \"we have\",\n",
        "  \"weren't\": \"were not\",\n",
        "  \"what'll\": \"what will\",\n",
        "  \"what'll've\": \"what will have\",\n",
        "  \"what're\": \"what are\",\n",
        "  \"what's\": \"what is\",\n",
        "  \"what've\": \"what have\",\n",
        "  \"when's\": \"when is\",\n",
        "  \"when've\": \"when have\",\n",
        "  \"where'd\": \"where did\",\n",
        "  \"where's\": \"where is\",\n",
        "  \"where've\": \"where have\",\n",
        "  \"who'll\": \"who will\",\n",
        "  \"who'll've\": \"who will have\",\n",
        "  \"who's\": \"who is\",\n",
        "  \"who've\": \"who have\",\n",
        "  \"why's\": \"why is\",\n",
        "  \"why've\": \"why have\",\n",
        "  \"will've\": \"will have\",\n",
        "  \"won't\": \"will not\",\n",
        "  \"won't've\": \"will not have\",\n",
        "  \"would've\": \"would have\",\n",
        "  \"wouldn't\": \"would not\",\n",
        "  \"wouldn't've\": \"would not have\",\n",
        "  \"y'all\": \"you all\",\n",
        "  \"y'all'd\": \"you all would\",\n",
        "  \"y'all'd've\": \"you all would have\",\n",
        "  \"y'all're\": \"you all are\",\n",
        "  \"y'all've\": \"you all have\",\n",
        "  \"you'd\": \"you would\",\n",
        "  \"you'd've\": \"you would have\",\n",
        "  \"you'll\": \"you will\",\n",
        "  \"you'll've\": \"you will have\",\n",
        "  \"you're\": \"you are\",\n",
        "  \"you've\": \"you have\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cHlSosxM07ne"
      },
      "outputs": [],
      "source": [
        "def regex(s):\n",
        "  s = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', s, flags=re.MULTILINE)\n",
        "  s = re.sub(r'\\<a href', ' ', s)\n",
        "  s = re.sub(r'&amp;', '', s) \n",
        "  s = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', s)\n",
        "  s = re.sub(r'<br />', ' ', s)\n",
        "  s = re.sub(r'\\'', ' ', s)\n",
        "  return s;\n",
        "\n",
        "def stops(s):\n",
        "  s = word_tokenize(s)\n",
        "  stops = set(stopwords.words('english'))\n",
        "  words = []\n",
        "  for word in s:\n",
        "    if not word in stops:\n",
        "      words.append(word)\n",
        "  return \" \".join(words)\n",
        "\n",
        "def clean_text(sentence):\n",
        "  sentence = sentence.lower()\n",
        "  sentence = sentence.split()\n",
        "  text = []\n",
        "  for word in sentence:\n",
        "    text.append(contractions[word] if word in contractions else word)\n",
        "  sentence = \" \".join(text)\n",
        "  sentence = regex(sentence)\n",
        "  sentence = stops(sentence)\n",
        "  sentence = WordPunctTokenizer().tokenize(sentence)\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NG_zLCiof7Qe"
      },
      "outputs": [],
      "source": [
        "# use the functions above to parse all words into separate elements in a list\n",
        "# and take out punctuation and stopwords\n",
        "for table in TABLES:\n",
        "  # clean first column\n",
        "  clean1 = list(map(clean_text, table['sentence_1']))\n",
        "  table['new_sentence_1'] = clean1\n",
        "  # clean second column\n",
        "  clean2 = list(map(clean_text, table['sentence_2']))\n",
        "  table['new_sentence_2'] = clean2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OdpMPqbtG_C1"
      },
      "outputs": [],
      "source": [
        "# lemmatize text, last step in cleaning words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for table in TABLES:\n",
        "  # lemmatize first column\n",
        "  lemma1 = list(map(\n",
        "    lambda word: list(map(lemmatizer.lemmatize, word)),\n",
        "    table['new_sentence_1']\n",
        "  ))\n",
        "  table['new_sentence_1'] = lemma1\n",
        "  # lemmatize second column\n",
        "  lemma2 = list(map(\n",
        "    lambda word: list(map(lemmatizer.lemmatize, word)),\n",
        "    table['new_sentence_2']\n",
        "  ))\n",
        "  table['new_sentence_2'] = lemma2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ae4oUFyCXUos"
      },
      "outputs": [],
      "source": [
        "# drop original text columns & reorder columns\n",
        "train.drop(['sentence_1', 'sentence_2'], axis=1, inplace=True)\n",
        "dev.drop(['sentence_1', 'sentence_2'], axis=1, inplace=True)\n",
        "test.drop(['sentence_1', 'sentence_2'], axis=1, inplace=True)\n",
        "new_cols = ['new_sentence_1', 'new_sentence_2', 'gold_label']\n",
        "train = train.reindex(columns=new_cols)\n",
        "dev = dev.reindex(columns=new_cols)\n",
        "test = test.reindex(columns=new_cols[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OjjHKb0wXuUm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "6e6c0279-6a19-40b8-ec0b-dfe047058e32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                        new_sentence_1  \\\n",
              "0  [democratic, candidate, also, began, announcing, fund, raising, total, wednesday, deadline, file, quarterly, report, federal, election, commission]   \n",
              "1                   [woman, exposed, sars, virus, hospital, health, care, worker, said, dr, colin, ’, cunha, ontario, ’, commissioner, public, health]   \n",
              "2                                                                                [said, problem, need, corrected, space, shuttle, fleet, cleared, fly]   \n",
              "3                                                         [representative, phoenix, based, u, haul, declined, comment, case, judge, opinion, released]   \n",
              "4                                                   [biggest, threat, order, seemed, looting, crime, including, robbery, prisoner, freed, saddam, war]   \n",
              "\n",
              "                                                                                                                                             new_sentence_2  \\\n",
              "0  [democratic, candidate, also, began, announcing, fund, raising, total, advance, deadline, today, file, quarterly, report, federal, election, commission]   \n",
              "1                              [woman, exposed, sars, virus, hospital, health, care, worker, said, dr, colin, cunha, ontario, commissioner, public, health]   \n",
              "2                                                                                            [said, prob, lem, need, corrected, space, shuttle, fleet, fly]   \n",
              "3                                                                                        [anthony, citrano, representative, whenu, declined, comment, case]   \n",
              "4                             [biggest, threat, order, seemed, looting, crime, including, robbery, ten, thousand, prisoner, mr, hussein, freed, last, year]   \n",
              "\n",
              "  gold_label  \n",
              "0          1  \n",
              "1          1  \n",
              "2          1  \n",
              "3          0  \n",
              "4          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c809d7c5-3ea4-4ac5-8ad3-3e9df2271b51\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>new_sentence_1</th>\n",
              "      <th>new_sentence_2</th>\n",
              "      <th>gold_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[democratic, candidate, also, began, announcing, fund, raising, total, wednesday, deadline, file, quarterly, report, federal, election, commission]</td>\n",
              "      <td>[democratic, candidate, also, began, announcing, fund, raising, total, advance, deadline, today, file, quarterly, report, federal, election, commission]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[woman, exposed, sars, virus, hospital, health, care, worker, said, dr, colin, ’, cunha, ontario, ’, commissioner, public, health]</td>\n",
              "      <td>[woman, exposed, sars, virus, hospital, health, care, worker, said, dr, colin, cunha, ontario, commissioner, public, health]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[said, problem, need, corrected, space, shuttle, fleet, cleared, fly]</td>\n",
              "      <td>[said, prob, lem, need, corrected, space, shuttle, fleet, fly]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[representative, phoenix, based, u, haul, declined, comment, case, judge, opinion, released]</td>\n",
              "      <td>[anthony, citrano, representative, whenu, declined, comment, case]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[biggest, threat, order, seemed, looting, crime, including, robbery, prisoner, freed, saddam, war]</td>\n",
              "      <td>[biggest, threat, order, seemed, looting, crime, including, robbery, ten, thousand, prisoner, mr, hussein, freed, last, year]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c809d7c5-3ea4-4ac5-8ad3-3e9df2271b51')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c809d7c5-3ea4-4ac5-8ad3-3e9df2271b51 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c809d7c5-3ea4-4ac5-8ad3-3e9df2271b51');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zkLdYoaYZebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d7af2804-7024-4119-d08b-e8dd2559a243"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                               new_sentence_1  \\\n",
              "0                                           [local, police, authority, treating, explosion, criminal, matter, nothing, ruled]   \n",
              "1  [report, show, drug, sold, canadian, pharmacy, manufactured, facility, approved, health, canada, fda, counterpart, canada]   \n",
              "2                                                                   [transition, slated, begin, later, june, 7, dayton, said]   \n",
              "3                      [like, viacom, ge, parent, nbc, also, seen, le, enthusiastic, bidder, compared, like, bronfman, davis]   \n",
              "4                                      [last, month, 62, spanish, peacekeeper, died, plane, crashed, turkey, returning, home]   \n",
              "\n",
              "                                                                                                                                     new_sentence_2  \\\n",
              "0                                               [acting, new, police, chief, francisco, ortiz, said, police, treating, explosion, criminal, matter]   \n",
              "1  [report, show, drug, sold, canadian, pharmacy, manufactured, facility, approved, health, canada, serf, similar, role, fda, canadian, government]   \n",
              "2                                                                                            [two, week, transition, period, begin, later, june, 7]   \n",
              "3                                                      [like, viacom, general, electric, seen, le, enthusiastic, bidder, compared, bronfman, davis]   \n",
              "4                                                 [another, disaster, 62, spanish, peacekeeper, killed, may, 26, plane, crashed, turkey, way, home]   \n",
              "\n",
              "  gold_label  \n",
              "0          0  \n",
              "1          1  \n",
              "2          1  \n",
              "3          1  \n",
              "4          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-832202ad-a6bd-4893-ab90-8e269208378f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>new_sentence_1</th>\n",
              "      <th>new_sentence_2</th>\n",
              "      <th>gold_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[local, police, authority, treating, explosion, criminal, matter, nothing, ruled]</td>\n",
              "      <td>[acting, new, police, chief, francisco, ortiz, said, police, treating, explosion, criminal, matter]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[report, show, drug, sold, canadian, pharmacy, manufactured, facility, approved, health, canada, fda, counterpart, canada]</td>\n",
              "      <td>[report, show, drug, sold, canadian, pharmacy, manufactured, facility, approved, health, canada, serf, similar, role, fda, canadian, government]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[transition, slated, begin, later, june, 7, dayton, said]</td>\n",
              "      <td>[two, week, transition, period, begin, later, june, 7]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[like, viacom, ge, parent, nbc, also, seen, le, enthusiastic, bidder, compared, like, bronfman, davis]</td>\n",
              "      <td>[like, viacom, general, electric, seen, le, enthusiastic, bidder, compared, bronfman, davis]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[last, month, 62, spanish, peacekeeper, died, plane, crashed, turkey, returning, home]</td>\n",
              "      <td>[another, disaster, 62, spanish, peacekeeper, killed, may, 26, plane, crashed, turkey, way, home]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-832202ad-a6bd-4893-ab90-8e269208378f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-832202ad-a6bd-4893-ab90-8e269208378f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-832202ad-a6bd-4893-ab90-8e269208378f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dev.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QhQHH_4QaL9_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "3efa6af1-3f7f-4a52-a457-da42c39c8ae8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                              new_sentence_1  \\\n",
              "0                                                                             [blackout, largely, preventable, said, spencer, abraham, u, energy, secretary]   \n",
              "1  [denver, based, natural, gas, producer, marketer, said, inaccurate, reporting, discovered, received, subpoena, u, commodity, future, trading, commission]   \n",
              "2                     [18, people, inside, building, two, visitor, 16, employee, including, harrison, ex, girlfriend, escaped, without, injury, aaron, said]   \n",
              "3                                                                                                 [billy, hodge, 11, engrossed, harry, potter, series, book]   \n",
              "4                                                                                     [family, stuck, highway, remained, car, used, cell, phone, call, home]   \n",
              "\n",
              "                                                                                                                                     new_sentence_2  \n",
              "0                                         [blackout, largely, preventable, energy, secretary, spencer, abraham, said, press, conference, afternoon]  \n",
              "1  [natural, gas, producer, marketer, said, inaccurate, reporting, discovered, response, subpoena, u, commodity, future, trading, commission, cftc]  \n",
              "2                                              [18, people, building, including, harrison, ex, girlfriend, injured, police, spokesman, aaron, said]  \n",
              "3                                                                                                     [indeed, harry, potter, series, stand, class]  \n",
              "4                                                                   [family, stuck, highway, urged, remain, car, use, cell, phone, case, emergency]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ac23cee-bebc-430f-b576-ed539a50385b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>new_sentence_1</th>\n",
              "      <th>new_sentence_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[blackout, largely, preventable, said, spencer, abraham, u, energy, secretary]</td>\n",
              "      <td>[blackout, largely, preventable, energy, secretary, spencer, abraham, said, press, conference, afternoon]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[denver, based, natural, gas, producer, marketer, said, inaccurate, reporting, discovered, received, subpoena, u, commodity, future, trading, commission]</td>\n",
              "      <td>[natural, gas, producer, marketer, said, inaccurate, reporting, discovered, response, subpoena, u, commodity, future, trading, commission, cftc]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[18, people, inside, building, two, visitor, 16, employee, including, harrison, ex, girlfriend, escaped, without, injury, aaron, said]</td>\n",
              "      <td>[18, people, building, including, harrison, ex, girlfriend, injured, police, spokesman, aaron, said]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[billy, hodge, 11, engrossed, harry, potter, series, book]</td>\n",
              "      <td>[indeed, harry, potter, series, stand, class]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[family, stuck, highway, remained, car, used, cell, phone, call, home]</td>\n",
              "      <td>[family, stuck, highway, urged, remain, car, use, cell, phone, case, emergency]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ac23cee-bebc-430f-b576-ed539a50385b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ac23cee-bebc-430f-b576-ed539a50385b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ac23cee-bebc-430f-b576-ed539a50385b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5honRC2Xta87"
      },
      "outputs": [],
      "source": [
        "n1 = train['new_sentence_1'] ; n2 = train['new_sentence_2']\n",
        "nd1 = dev['new_sentence_1'] ; nd2 = dev['new_sentence_2']\n",
        "nx1 = test['new_sentence_1'] ; nx2 = test['new_sentence_2']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch length of each row of word\n",
        "len_n1 = [len(n1[i]) for i in range(len(n1))]\n",
        "len_n2 = [len(n2[i]) for i in range(len(n2))]\n",
        "len_nd1 = [len(nd1[i]) for i in range(len(nd1))]\n",
        "len_nd2 = [len(nd2[i]) for i in range(len(nd2))]\n",
        "len_nx1 = [len(nx1[i]) for i in range(len(nx1))]\n",
        "len_nx2 = [len(nx2[i]) for i in range(len(nx2))]\n",
        "\n",
        "# calculate differences and average for each pair of columns\n",
        "lenavg_train = [((len_n1[i] + len_n2[i]) / 2) for i in range(len(len_n1))]\n",
        "lenavg_dev = [((len_nd1[i] + len_nd2[i]) / 2) for i in range(len(len_nd1))]\n",
        "lenavg_test = [((len_nx1[i] + len_nx2[i]) / 2) for i in range(len(len_nx1))]\n",
        "lendiff_train = [abs(len_n1[i] - len_n2[i]) / 2 for i in range(len(len_n1))]\n",
        "lendiff_dev = [abs(len_nd1[i] - len_nd2[i]) for i in range(len(len_nd1))]\n",
        "lendiff_test = [abs(len_nx1[i] - len_nx2[i]) for i in range(len(len_nx1))]"
      ],
      "metadata": {
        "id": "AGei8fK7DXrQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cyOMhaXe-iZH"
      },
      "outputs": [],
      "source": [
        "# separate TfidfVectorizer's for each array/Series of text data\n",
        "tfidf_n1 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=\" \".join, stop_words='english', lowercase=False)\n",
        "tfidf_n2 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=\" \".join, stop_words='english', lowercase=False)\n",
        "tfidf_nd1 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=\" \".join, stop_words='english', lowercase=False)\n",
        "tfidf_nd2 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=\" \".join, stop_words='english', lowercase=False)\n",
        "tfidf_nx1 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=\" \".join, stop_words='english', lowercase=False)\n",
        "tfidf_nx2 = TfidfVectorizer(use_idf=True, smooth_idf=True, preprocessor=\" \".join, stop_words='english', lowercase=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1vZ-8MK3tlNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e855ce0f-0055-4db6-898b-8c77fef7470a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3876\n",
            "702\n",
            "951\n"
          ]
        }
      ],
      "source": [
        "# matrices of numbers from TfidfVectorizer\n",
        "arr_n1 = tfidf_n1.fit_transform(n1).toarray()\n",
        "arr_n2 = tfidf_n2.fit_transform(n2).toarray()\n",
        "arr_nd1 = tfidf_nd1.fit_transform(nd1).toarray()\n",
        "arr_nd2 = tfidf_nd2.fit_transform(nd2).toarray()\n",
        "arr_nx1 = tfidf_nx1.fit_transform(nx1).toarray()\n",
        "arr_nx2 = tfidf_nx2.fit_transform(nx2).toarray()\n",
        "\n",
        "print(len(arr_n1)); print(len(arr_nd1)); print(len(arr_nx1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IIlDvRrRteQA"
      },
      "outputs": [],
      "source": [
        "# add x number of arrays of same length to accomodate for missing words\n",
        "# get words that are available in one set but not another\n",
        "train_1_not_2 = list(set(tfidf_n1.get_feature_names_out()).difference(tfidf_n2.get_feature_names_out()))\n",
        "train_2_not_1 = list(set(tfidf_n2.get_feature_names_out()).difference(tfidf_n1.get_feature_names_out()))\n",
        "dev_1_not_2 = list(set(tfidf_nd1.get_feature_names_out()).difference(tfidf_nd2.get_feature_names_out()))\n",
        "dev_2_not_1 = list(set(tfidf_nd2.get_feature_names_out()).difference(tfidf_nd1.get_feature_names_out()))\n",
        "test_1_not_2 = list(set(tfidf_nx1.get_feature_names_out()).difference(tfidf_nx2.get_feature_names_out()))\n",
        "test_2_not_1 = list(set(tfidf_nx2.get_feature_names_out()).difference(tfidf_nx1.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "poahUeE7PwVt"
      },
      "outputs": [],
      "source": [
        "# take each existing matrix (2 cells above) and add empty rows\n",
        "\n",
        "# change feature names to fit all words\n",
        "new_arr_n1 = []\n",
        "for i in range(len(arr_n1)):\n",
        "    temp = list(arr_n1[i])\n",
        "    temp.extend([0] * len(train_2_not_1))\n",
        "    new_arr_n1.append(temp)\n",
        "arr_n1 = np.array(new_arr_n1)\n",
        "\n",
        "new_arr_n2 = []\n",
        "for i in range(len(arr_n2)):\n",
        "    temp = list(arr_n2[i])\n",
        "    temp.extend([0] * len(train_1_not_2))\n",
        "    new_arr_n2.append(temp)\n",
        "arr_n2 = np.array(new_arr_n2)\n",
        "\n",
        "new_arr_nx1 = []\n",
        "for i in range(len(arr_nx1)):\n",
        "    temp = list(arr_nx1[i])\n",
        "    temp.extend([0] * len(test_2_not_1))\n",
        "    new_arr_nx1.append(temp)\n",
        "arr_nx1 = np.array(new_arr_nx1)\n",
        "\n",
        "new_arr_nx2 = []\n",
        "for i in range(len(arr_nx2)):\n",
        "    temp = list(arr_nx2[i])\n",
        "    temp.extend([0] * len(test_1_not_2))\n",
        "    new_arr_nx2.append(temp)\n",
        "arr_nx2 = np.array(new_arr_nx2)\n",
        "\n",
        "new_arr_nd1 = []\n",
        "for i in range(len(arr_nd1)):\n",
        "    temp = list(arr_nd1[i])\n",
        "    temp.extend([0] * len(dev_2_not_1))\n",
        "    new_arr_nd1.append(temp)\n",
        "arr_nd1 = np.array(new_arr_nd1)\n",
        "\n",
        "new_arr_nd2 = []\n",
        "for i in range(len(arr_nd2)):\n",
        "    temp = list(arr_nd2[i])\n",
        "    temp.extend([0] * len(dev_1_not_2))\n",
        "    new_arr_nd2.append(temp)\n",
        "arr_nd2 = np.array(new_arr_nd2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "O81YbAc0PwK-"
      },
      "outputs": [],
      "source": [
        "# conjoin features\n",
        "features_train = list(tfidf_n1.get_feature_names_out())\n",
        "extra_train = list(train_2_not_1)\n",
        "features_train.extend(extra_train)\n",
        "\n",
        "features_dev = list(tfidf_nd1.get_feature_names_out())\n",
        "extra_dev = list(dev_2_not_1)\n",
        "features_dev.extend(extra_dev)\n",
        "\n",
        "features_test = list(tfidf_nx1.get_feature_names_out())\n",
        "extra_test = list(test_2_not_1)\n",
        "features_test.extend(extra_test)\n",
        "\n",
        "# all lengths are to be equal to set.union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bQR7hto3e27n"
      },
      "outputs": [],
      "source": [
        "# process separate DataFrames for each table (TFIDF)\n",
        "def process_tfidf(table, values):\n",
        "  return pd.DataFrame(\n",
        "      data=table.T, index=values, columns=([f'tfidf_{i}' for i in range(len(table))])\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7b40n4OlKT3N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "431bd2b0-2796-4f9c-dfe7-3c6d3f8b6758"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         tfidf_0  tfidf_1  tfidf_2  tfidf_3  tfidf_4  tfidf_5  tfidf_6  \\\n",
              "00           0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
              "000          0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
              "004          0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
              "009          0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
              "01           0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
              "...          ...      ...      ...      ...      ...      ...      ...   \n",
              "3805         0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
              "gul          0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
              "alike        0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
              "printed      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
              "regent       0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
              "\n",
              "          tfidf_7  tfidf_8  tfidf_9  ...  tfidf_3866  tfidf_3867  tfidf_3868  \\\n",
              "00       0.000000      0.0      0.0  ...         0.0         0.0         0.0   \n",
              "000      0.213551      0.0      0.0  ...         0.0         0.0         0.0   \n",
              "004      0.000000      0.0      0.0  ...         0.0         0.0         0.0   \n",
              "009      0.000000      0.0      0.0  ...         0.0         0.0         0.0   \n",
              "01       0.000000      0.0      0.0  ...         0.0         0.0         0.0   \n",
              "...           ...      ...      ...  ...         ...         ...         ...   \n",
              "3805     0.000000      0.0      0.0  ...         0.0         0.0         0.0   \n",
              "gul      0.000000      0.0      0.0  ...         0.0         0.0         0.0   \n",
              "alike    0.000000      0.0      0.0  ...         0.0         0.0         0.0   \n",
              "printed  0.000000      0.0      0.0  ...         0.0         0.0         0.0   \n",
              "regent   0.000000      0.0      0.0  ...         0.0         0.0         0.0   \n",
              "\n",
              "         tfidf_3869  tfidf_3870  tfidf_3871  tfidf_3872  tfidf_3873  \\\n",
              "00              0.0         0.0         0.0         0.0         0.0   \n",
              "000             0.0         0.0         0.0         0.0         0.0   \n",
              "004             0.0         0.0         0.0         0.0         0.0   \n",
              "009             0.0         0.0         0.0         0.0         0.0   \n",
              "01              0.0         0.0         0.0         0.0         0.0   \n",
              "...             ...         ...         ...         ...         ...   \n",
              "3805            0.0         0.0         0.0         0.0         0.0   \n",
              "gul             0.0         0.0         0.0         0.0         0.0   \n",
              "alike           0.0         0.0         0.0         0.0         0.0   \n",
              "printed         0.0         0.0         0.0         0.0         0.0   \n",
              "regent          0.0         0.0         0.0         0.0         0.0   \n",
              "\n",
              "         tfidf_3874  tfidf_3875  \n",
              "00              0.0         0.0  \n",
              "000             0.0         0.0  \n",
              "004             0.0         0.0  \n",
              "009             0.0         0.0  \n",
              "01              0.0         0.0  \n",
              "...             ...         ...  \n",
              "3805            0.0         0.0  \n",
              "gul             0.0         0.0  \n",
              "alike           0.0         0.0  \n",
              "printed         0.0         0.0  \n",
              "regent          0.0         0.0  \n",
              "\n",
              "[11713 rows x 3876 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c8ce604-18f7-4b6c-a5a7-d98981d2f1ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tfidf_0</th>\n",
              "      <th>tfidf_1</th>\n",
              "      <th>tfidf_2</th>\n",
              "      <th>tfidf_3</th>\n",
              "      <th>tfidf_4</th>\n",
              "      <th>tfidf_5</th>\n",
              "      <th>tfidf_6</th>\n",
              "      <th>tfidf_7</th>\n",
              "      <th>tfidf_8</th>\n",
              "      <th>tfidf_9</th>\n",
              "      <th>...</th>\n",
              "      <th>tfidf_3866</th>\n",
              "      <th>tfidf_3867</th>\n",
              "      <th>tfidf_3868</th>\n",
              "      <th>tfidf_3869</th>\n",
              "      <th>tfidf_3870</th>\n",
              "      <th>tfidf_3871</th>\n",
              "      <th>tfidf_3872</th>\n",
              "      <th>tfidf_3873</th>\n",
              "      <th>tfidf_3874</th>\n",
              "      <th>tfidf_3875</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.213551</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>004</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>009</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>01</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3805</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gul</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alike</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>printed</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>regent</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11713 rows × 3876 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c8ce604-18f7-4b6c-a5a7-d98981d2f1ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c8ce604-18f7-4b6c-a5a7-d98981d2f1ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c8ce604-18f7-4b6c-a5a7-d98981d2f1ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# for training column 1\n",
        "df_n1 = process_tfidf(arr_n1, features_train)\n",
        "# for training column 2\n",
        "df_n2 = process_tfidf(arr_n2, features_train)\n",
        "# for dev column 1\n",
        "df_nd1 = process_tfidf(arr_nd1, features_dev)\n",
        "# for dev column 2\n",
        "df_nd2 = process_tfidf(arr_nd2, features_dev)\n",
        "# for test column 1\n",
        "df_nx1 = process_tfidf(arr_nx1, features_test)\n",
        "# for test column 2\n",
        "df_nx2 = process_tfidf(arr_nx2, features_test)\n",
        "# example\n",
        "df_n1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3cnLeeAIm7hR"
      },
      "outputs": [],
      "source": [
        "# test cosine similarity of two matrices using scipy\n",
        "\n",
        "def calculate_cosine(n1, n2):\n",
        "  cos = []\n",
        "  for i in range(len(n1)):\n",
        "    temp1, temp2 = n1[i], n2[i]\n",
        "    c = sp.distance.cosine(temp1, temp2)\n",
        "    cos.append(c)\n",
        "  return cos\n",
        "\n",
        "cosine_results_train = calculate_cosine(arr_n1, arr_n2)\n",
        "cosine_results_dev = calculate_cosine(arr_nd1, arr_nd2)\n",
        "cosine_results_test = calculate_cosine(arr_nx1, arr_nx2)\n",
        "\n",
        "# HOW IT WORKS: \n",
        "# sp.distance.cosine(num[], num[]) -> int\n",
        "# input1 <- first num[]\n",
        "# input2 <- second num[]\n",
        "# return (\n",
        "#   1 - (\n",
        "#     input1 (dot) input2 \n",
        "#     /                  \n",
        "#     np.sqrt( add x^2 for x in input1 ) x np.sqrt( add x^2 for x in input2 )\n",
        "#   )\n",
        "# )\n",
        "# MORE: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "njSqX2fBxikj"
      },
      "outputs": [],
      "source": [
        "# save text_similarities in pickle file since they take too long\n",
        "pickle_ts1 = f'{SRC}/text_similarities_train.pickle'\n",
        "pickle_ts2 = f'{SRC}/text_similarities_dev.pickle'\n",
        "pickle_ts3 = f'{SRC}/text_similarities_test.pickle'\n",
        "pickle_cs1 = f'{SRC}/compare_train.pickle'\n",
        "pickle_cs2 = f'{SRC}/compare_dev.pickle'\n",
        "pickle_cs3 = f'{SRC}/compare_test.pickle'\n",
        "\n",
        "if not os.path.exists(pickle_ts1):\n",
        "  open(pickle_ts1, 'wb').close()\n",
        "if not os.path.exists(pickle_ts2):\n",
        "  open(pickle_ts2, 'wb').close()\n",
        "if not os.path.exists(pickle_ts3):\n",
        "  open(pickle_ts3, 'wb').close()\n",
        "if not os.path.exists(pickle_cs1):\n",
        "  open(pickle_cs1, 'wb').close()\n",
        "if not os.path.exists(pickle_cs2):\n",
        "  open(pickle_cs2, 'wb').close()\n",
        "if not os.path.exists(pickle_cs3):\n",
        "  open(pickle_cs3, 'wb').close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KBSh__5ZoYGV"
      },
      "outputs": [],
      "source": [
        "# try gensim\n",
        "# source: https://betterprogramming.pub/introduction-to-gensim-calculating-text-similarity-9e8b55de342d\n",
        "from gensim import corpora, models, similarities\n",
        "\n",
        "text_similarities_train = []\n",
        "if not os.path.getsize(pickle_ts1) > 0:\n",
        "  for IND in range(len(arr_n1)):\n",
        "    #start = 0 if IND < len(arr_n1)-500 else len(arr_n1)-500 \n",
        "    end = IND+500\n",
        "    if (end > len(arr_n1)):\n",
        "      end = len(arr_n1)\n",
        "    text_a = n1[0:end]     # require array for dictionary\n",
        "    text_b = n2[IND]\n",
        "    dictionary = corpora.Dictionary(text_a)\n",
        "    corpus = [dictionary.doc2bow(t) for t in text_a]  # put each individual entry in doc2bow\n",
        "    tfidf = models.TfidfModel(corpus)\n",
        "    kw_vector = dictionary.doc2bow(text_b)\n",
        "    index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=len(dictionary.token2id))\n",
        "    sim = index[tfidf[kw_vector]]\n",
        "    text_similarities_train.append(sim[IND])\n",
        "  with open(pickle_ts1, 'wb') as writefile:\n",
        "    pickle.dump(text_similarities_train, writefile)\n",
        "    writefile.close()\n",
        "else:\n",
        "  readfile = open(pickle_ts1, 'rb')\n",
        "  text_similarities_train = pickle.load(readfile)\n",
        "  readfile.close()\n",
        "\n",
        "\n",
        "text_similarities_dev = []\n",
        "if not os.path.getsize(pickle_ts2) > 0:\n",
        "  for IND in range(len(arr_nd1)):\n",
        "    end = IND+500\n",
        "    if (end > len(arr_nd1)):\n",
        "      end = len(arr_nd1)\n",
        "    text_a = nd1[0:end]    \n",
        "    text_b = nd2[IND]\n",
        "    dictionary = corpora.Dictionary(text_a)\n",
        "    corpus = [dictionary.doc2bow(t) for t in text_a] \n",
        "    tfidf = models.TfidfModel(corpus)\n",
        "    kw_vector = dictionary.doc2bow(text_b)\n",
        "    index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=len(dictionary.token2id))\n",
        "    sim = index[tfidf[kw_vector]]\n",
        "    text_similarities_dev.append(sim[IND])\n",
        "  with open(pickle_ts2, 'wb') as writefile:\n",
        "    pickle.dump(text_similarities_train, writefile)\n",
        "    writefile.close()\n",
        "else:\n",
        "  readfile = open(pickle_ts2, 'rb')\n",
        "  text_similarities_dev = pickle.load(readfile)\n",
        "  readfile.close()\n",
        "\n",
        "\n",
        "text_similarities_test = []\n",
        "if not os.path.getsize(pickle_ts3) > 0:\n",
        "  for IND in range(len(arr_nx1)):\n",
        "    end = IND+500\n",
        "    if (end > len(arr_nx1)):\n",
        "      end = len(arr_nx1)\n",
        "    text_a = nx1[0:end] \n",
        "    text_b = nx2[IND]\n",
        "    dictionary = corpora.Dictionary(text_a)\n",
        "    corpus = [dictionary.doc2bow(t) for t in text_a] \n",
        "    tfidf = models.TfidfModel(corpus)\n",
        "    kw_vector = dictionary.doc2bow(text_b)\n",
        "    index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=len(dictionary.token2id))\n",
        "    sim = index[tfidf[kw_vector]]\n",
        "    text_similarities_test.append(sim[IND])\n",
        "  with open(pickle_ts3, 'wb') as writefile:\n",
        "    pickle.dump(text_similarities_train, writefile)\n",
        "    writefile.close()\n",
        "else:\n",
        "  readfile = open(pickle_ts3, 'rb')\n",
        "  text_similarities_test = pickle.load(readfile)\n",
        "  readfile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbK2UVis9fhF"
      },
      "source": [
        "<h3>\n",
        "  Using Algorithms\n",
        "</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-JxjHsIk8Y7r"
      },
      "outputs": [],
      "source": [
        "def print_results(a, p):\n",
        "  lbl = ['accuracy', 'precision', 'recall', 'f1']\n",
        "\n",
        "  ind = ['weighted', 'micro', 'macro']\n",
        "  acc = []\n",
        "  pre = []\n",
        "  rec = []\n",
        "  ff = []\n",
        "\n",
        "  acc_score = accuracy_score(a, p)\n",
        "  for i in range(len(ind)):\n",
        "    acc.append(acc_score)\n",
        "    pre.append(\n",
        "        precision_score(a, p, average=ind[i])\n",
        "    )\n",
        "    rec.append(\n",
        "        recall_score(a, p, average=ind[i])\n",
        "    )\n",
        "    ff.append(\n",
        "        f1_score(a, p, average=ind[i])\n",
        "    )\n",
        "\n",
        "  dta = [acc, pre, rec, ff]\n",
        "  df = pd.DataFrame(dta, columns=ind, index=lbl)\n",
        "\n",
        "  ts = str(calendar.timegm(time.gmtime()))\n",
        "  filename = f'{SRC}/results-{ts}.txt'\n",
        "\n",
        "  with open(filename, 'a') as f:\n",
        "    dfAsString = df.to_string(header=True, index=True)\n",
        "    f.write(dfAsString + \"\\n\")\n",
        "    f.close()\n",
        "\n",
        "  print(' ::: weighted, micro, macro :::')\n",
        "  print('ACCURACY: ', acc_score)\n",
        "  print('PRECISION: ', pre)\n",
        "  print('RECALL: ', rec)\n",
        "  print('F1-SCORE: ', ff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aFve0A8W6-w1"
      },
      "outputs": [],
      "source": [
        "# before performing algorithms, we want to know whether the following influences the decision of accurately predicting the gold label:\n",
        "# - cosine similarity\n",
        "# - similarity based on sparse matrix\n",
        "# - average length in pair of text\n",
        "# - difference in length of pair of text\n",
        "# - & for train/dev comparisons, add gold_label\n",
        "\n",
        "CL = ['cosine', 'similarity', 'length_average', 'length_difference', 'label']\n",
        "\n",
        "compare_data_train = []\n",
        "if not os.path.getsize(pickle_cs1) > 0:\n",
        "  for i in range(len(gold_train)):\n",
        "    temp = (cosine_results_train[i], text_similarities_train[i], lenavg_train[i], lendiff_train[i], gold_train[i])\n",
        "    compare_data_train.append(temp)\n",
        "  with open(pickle_cs1, 'wb') as writefile:\n",
        "    pickle.dump(compare_data_train, writefile)\n",
        "    writefile.close()\n",
        "else:\n",
        "  readfile = open(pickle_cs1, 'rb')\n",
        "  compare_data_train = pickle.load(readfile)\n",
        "  readfile.close()\n",
        "compare_train = pd.DataFrame(data=compare_data_train, columns=CL)\n",
        "\n",
        "\n",
        "compare_data_dev = []\n",
        "if not os.path.getsize(pickle_cs2) > 0:\n",
        "  for i in range(len(gold_dev)):\n",
        "    temp = (cosine_results_dev[i], text_similarities_dev[i], lenavg_dev[i], lendiff_dev[i], gold_dev[i])\n",
        "    compare_data_dev.append(temp)\n",
        "  with open(pickle_cs2, 'wb') as writefile:\n",
        "    pickle.dump(compare_data_dev, writefile)\n",
        "    writefile.close()\n",
        "else:\n",
        "  readfile = open(pickle_cs2, 'rb')\n",
        "  compare_data_dev = pickle.load(readfile)\n",
        "  readfile.close()\n",
        "compare_dev = pd.DataFrame(data=compare_data_dev, columns=CL)\n",
        "\n",
        "\n",
        "compare_data_test = []\n",
        "if not os.path.getsize(pickle_cs3) > 0:\n",
        "  for i in range(len(cosine_results_test)):\n",
        "    temp = (cosine_results_test[i], text_similarities_test[i], lenavg_test[i], lendiff_test[i])\n",
        "    compare_data_test.append(temp)\n",
        "  with open(pickle_cs3, 'wb') as writefile:\n",
        "    pickle.dump(compare_data_test, writefile)\n",
        "    writefile.close()\n",
        "else:\n",
        "  readfile = open(pickle_cs3, 'rb')\n",
        "  compare_data_test = pickle.load(readfile)\n",
        "  readfile.close()\n",
        "compare_test = pd.DataFrame(data=compare_data_test, columns=CL[0:4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bgA8u4V0m2Un"
      },
      "outputs": [],
      "source": [
        "# logistic regression (condition: estimate label based on cosine AND gensim similarlity)\n",
        "x = compare_train.drop('label', axis=1)\n",
        "y = compare_train['label']\n",
        "\n",
        "lr_1 = LogisticRegression()\n",
        "\n",
        "# 1 -> training data for training    -> matrix\n",
        "# 2 -> data for prediction (testing) -> matrix\n",
        "# 3 -> label column for training                          -> series\n",
        "# 4 -> data for comparing prediction results (testing)    -> series\n",
        "x_train, x_test, y_train, y_test = train_test_split(x.values, y.values, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TV37uxuW9kN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e4c509-bcd7-4bfb-9d28-7483be72251a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ::: weighted, micro, macro :::\n",
            "ACCURACY:  0.7626827171109201\n",
            "PRECISION:  [0.7293951145350924, 0.7626827171109201, 0.6615659243548957]\n",
            "RECALL:  [0.7626827171109201, 0.7626827171109201, 0.5915472928584018]\n",
            "F1-SCORE:  [0.7307290257469694, 0.7626827171109202, 0.6005067903938827]\n"
          ]
        }
      ],
      "source": [
        "# start with training and predict via training data (split)\n",
        "lr_1.fit(x_train, y_train)\n",
        "preds_1 = lr_1.predict(x_test)\n",
        "\n",
        "print_results(y_test, preds_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "5zE5r09p9kSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab76cd32-bd2f-43db-c27f-e7ca9c565cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ::: weighted, micro, macro :::\n",
            "ACCURACY:  0.594017094017094\n",
            "PRECISION:  [0.7143729641693811, 0.594017094017094, 0.7143729641693811]\n",
            "RECALL:  [0.594017094017094, 0.594017094017094, 0.594017094017094]\n",
            "F1-SCORE:  [0.5277302394750198, 0.594017094017094, 0.5277302394750198]\n"
          ]
        }
      ],
      "source": [
        "# next, try with training and predict via dev data\n",
        "a = compare_dev.drop('label', axis=1)\n",
        "b = compare_dev['label']\n",
        "\n",
        "# x, y, a, b\n",
        "lr_1.fit(x.values, y.values)\n",
        "preds_2 = lr_1.predict(a.values)\n",
        "\n",
        "print_results(b.values, preds_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "a6RmLTf79kWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ef845d-5438-4df0-85b4-bb8cc025329b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1' '1' '1' ... '1' '1' '1']\n"
          ]
        }
      ],
      "source": [
        "# use same logistic regression for predicting gold labels\n",
        "final_preds = lr_1.predict(compare_data_test)\n",
        "print(final_preds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE new file for predicted labels (from test)\n",
        "final_results_file = f'{SRC}/StephenHullender_test_result.txt'\n",
        "assert len(final_instance_ids) == len(final_preds)\n",
        "with open(final_results_file, 'a') as f:\n",
        "    for i in range(len(final_preds)):\n",
        "      f.write(str(final_instance_ids[i]) + '\\t' + str(final_preds[i]) + \"\\n\")\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "VkkGPNa24eMR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwuZ0o4husal"
      },
      "source": [
        "<h3>\n",
        "  Sources\n",
        "</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFic5mrWuvXf"
      },
      "source": [
        "<span>\n",
        "  External Links\n",
        "</span>\n",
        "<br/>\n",
        "<ul>\n",
        "<li><a href=\"https://github.com/stephull/MLMidTerm\" target='_blank'>GitHub (Forked Repo)</a></li>\n",
        "</ul>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}